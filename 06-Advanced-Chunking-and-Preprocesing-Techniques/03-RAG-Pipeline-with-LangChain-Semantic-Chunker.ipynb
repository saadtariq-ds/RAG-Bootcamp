{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c2e073a",
   "metadata": {},
   "source": [
    "## Setup and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05217391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.schema.runnable import RunnableLambda, RunnableMap\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35a6834c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a141f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "772d135c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "llm = init_chat_model(model=\"groq:openai/gpt-oss-20b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc24073",
   "metadata": {},
   "source": [
    "## Load the Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "292076b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(file_path=\"data.txt\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a0f23e",
   "metadata": {},
   "source": [
    "## Create Semantic Chunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6a7c5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunker = SemanticChunker(embeddings=embeddings)\n",
    "\n",
    "chunks = chunker.split_documents(documents=documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43c68ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Chunk 1: \n",
      "LangChain is a framework for building applications with LLMs. LangChain provides modular abstractions to combine LLMs with tools like OpenAI and Pinecone. You can create chains, agents, memory and retrievers.\n",
      "\n",
      " Chunk 2: \n",
      "The Eiffel Tower is located in Paris. France is a popular tourist destination\n"
     ]
    }
   ],
   "source": [
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"\\n Chunk {i+1}: \\n{chunk.page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d946f81",
   "metadata": {},
   "source": [
    "## Storing Data into Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3e17932",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = FAISS.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418b09fa",
   "metadata": {},
   "source": [
    "## Create Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e65a70f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=' Answer the question based on the following context:\\n\\nContext: {context}\\n\\nQuestion: {question}\\n')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\"\" Answer the question based on the following context:\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template=template)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69abea82",
   "metadata": {},
   "source": [
    "## Creating RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4841182f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    RunnableMap(\n",
    "        {\n",
    "            \"context\": lambda x: retriever.invoke(x[\"question\"]),\n",
    "            \"question\": lambda x: x[\"question\"]\n",
    "        }\n",
    "    )\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1db82cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChain is a framework for building applications that use large language models (LLMs). It provides modular abstractions so developers can combine LLMs with tools such as OpenAI, Pinecone, and others, and create components like chains, agents, memory, and retrievers to build more complex, interactive AI applications.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = {\"question\": \"What is Langchain used for?\"}\n",
    "\n",
    "result = rag_chain.invoke(input=question)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6dde4b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'France is famous mainly for its rich cultural heritage and iconic landmarks.  \\n- **Eiffel Tower**: The towering iron lattice in Paris is one of the most recognizable symbols of France worldwide.  \\n- **Paris**: As the capital, Paris attracts millions of visitors each year with its art, fashion, cuisine, and historic sites.  \\n- **Tourism**: The combination of these attractions, along with Franceâ€™s reputation for cuisine, fashion, and history, makes it a top tourist destination.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = {\"question\": \"Why France is so famous?\"}\n",
    "\n",
    "result = rag_chain.invoke(input=question)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47404718",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG-Bootcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
