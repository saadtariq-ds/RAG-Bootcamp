{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fb5013b",
   "metadata": {},
   "source": [
    "## Setup and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e2d3a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1db7c51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4794124c",
   "metadata": {},
   "source": [
    "## Loading Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c96bff6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data.txt'}, page_content='LangChain is a framework for building applications with LLMs.\\nLangChain provides modular abstractions to combine LLMs with tools like OpenAI and Pinecone.\\nYou can create chains, agents, memory and retrievers.\\nThe Eiffel Tower is located in Paris.\\nFrance is a popular tourist destination')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = TextLoader(file_path=\"data.txt\")\n",
    "text = loader.load()\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb4dca7",
   "metadata": {},
   "source": [
    "## 1. Split into Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0eed680a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LangChain is a framework for building applications with LLMs.',\n",
       " 'LangChain provides modular abstractions to combine LLMs with tools like OpenAI and Pinecone.',\n",
       " 'You can create chains, agents, memory and retrievers.',\n",
       " 'The Eiffel Tower is located in Paris.',\n",
       " 'France is a popular tourist destination']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = text[0].page_content\n",
    "\n",
    "sentences = [sentence.strip() for sentence in text.split(\"\\n\") if sentence.strip()]\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbb8946",
   "metadata": {},
   "source": [
    "## 2. Embed Each Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9922e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.encode(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab21538b",
   "metadata": {},
   "source": [
    "## 3. Initialize Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08739801",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.7\n",
    "chunks = []\n",
    "\n",
    "current_chunk = [sentences[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58b358f",
   "metadata": {},
   "source": [
    "## 4. Semantic Grouping Based on Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ea92c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Semantic Chunks:\n",
      "Chunk 1: \n",
      "LangChain is a framework for building applications with LLMs. LangChain provides modular abstractions to combine LLMs with tools like OpenAI and Pinecone.\n",
      "Chunk 2: \n",
      "You can create chains, agents, memory and retrievers.\n",
      "Chunk 3: \n",
      "The Eiffel Tower is located in Paris.\n",
      "Chunk 4: \n",
      "France is a popular tourist destination\n"
     ]
    }
   ],
   "source": [
    "for sentence in range(1, len(sentences)):\n",
    "    similarity = cosine_similarity(\n",
    "        X=[embeddings[sentence - 1]],\n",
    "        Y=[embeddings[sentence]]\n",
    "    )[0][0]\n",
    "\n",
    "    if similarity >= threshold:\n",
    "        current_chunk.append(sentences[sentence])\n",
    "    else:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "        current_chunk=[sentences[sentence]]\n",
    "\n",
    "chunks.append(\" \".join(current_chunk))\n",
    "\n",
    "print(\"\\n Semantic Chunks:\")\n",
    "for idx, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {idx+1}: \\n{chunk}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5de0ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG-Bootcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
