{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37b57666",
   "metadata": {},
   "source": [
    "## Setup and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fc4b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableMap\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471017b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2995e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"HUGGINGFACE_API_KEY\"] = os.getenv(\"HUGGINGFACE_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1af1e92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model=\"all-MiniLM-L6-v2\")\n",
    "# llm = init_chat_model(model=\"groq:gemma2-9b-it\")\n",
    "llm = init_chat_model(model=\"openai:o4-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba395a7c",
   "metadata": {},
   "source": [
    "## Document Loading and Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0123fed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is an open-source framework designed for developing applications powered by large language models (LLMs). It simplifies the process of building, managing, and scaling complex chains of thought by abstracting prompt management, retrieval, memory, and agent orchestration. Developers can use'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='At the heart of LangChain lies the concept of chains, which are sequences of calls to LLMs and other tools. Chains can be simple, such as a single prompt fed to an LLM, or complex, involving multiple conditionally executed steps. LangChain makes it easy to compose and reuse chains using standard'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='knowledge is fetched and injected into the LLM prompt to enhance accuracy and reduce hallucination. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain also supports hybrid retrieval, which combines keyword-based (sparse) retrieval methods like BM25 with embedding-based (dense) retrieval. This ensures better recall by catching both exact term matches and semantically similar content. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='like web search, calculators, code execution environments, and custom APIs. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain agents operate using a planner-executor model, where the agent plans out a sequence of tool invocations to achieve a goal. This can include dynamic decision-making, branching logic, and context-aware memory use across steps. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain offers memory modules like ConversationBufferMemory and ConversationSummaryMemory. These allow the LLM to maintain awareness of previous conversation turns or summarize long interactions to fit within token limits. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Prompt engineering is central to LangChainâ€™s design. It provides templating capabilities, input variables, formatting options, and prompt chaining. Developers can reuse prompt templates across different chains and even nest them. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is compatible with multiple LLM providers including OpenAI, Anthropic, Cohere, Hugging Face, and more. This flexibility ensures that developers can switch between models without rewriting core logic. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain workflows are modular and composable. Components like retrievers, memories, agents, and chains can be easily combined and reused. This makes it ideal for building scalable, maintainable LLM applications. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is a multi-agent orchestration framework designed to build collaborative LLM-powered agents. It enables developers to structure agents into organized crews that work together to complete tasks by dividing responsibilities, sharing context, and dynamically communicating with one another. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI builds on the concept of autonomous agents but enhances it by allowing agents to form structured workflows. Each agent in a crew has a defined role, such as researcher, planner, or executor, and operates semi-independently within a collaborative context. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI agents are defined with a purpose, a goal, and a set of tools they can use. The framework ensures that each agent stays on task and contributes meaningfully to the overall crew objective. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content=\"One of CrewAI's core innovations is the use of agent context-sharing, where agents pass intermediate data to one another in a structured manner. This leads to emergent behaviors like delegation, consultation, and review among agents. (v1)\"),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is especially useful in multi-step workflows like market research, legal document analysis, product development, and coding assistants, where complex tasks benefit from specialization and collaboration. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='The framework supports full traceability of agent decisions and interactions, making debugging and transparency easier compared to standalone agent setups. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Developers can define a crew using a YAML or JSON-like configuration, specifying agent roles, goals, memory, and tools. CrewAI then orchestrates the agent loop and handles turn-taking and decision-making autonomously. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI supports multiple LLM backends and includes support for streaming, parallel execution, and asynchronous tool invocation, making it suitable for both fast-prototyping and production-ready systems. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='By enabling structured agent collaboration, CrewAI empowers teams to build intelligent systems that scale both horizontally (more agents) and vertically (more reasoning depth). (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is an open-source framework designed for developing applications powered by large language models (LLMs). It simplifies the process of building, managing, and scaling complex chains of thought by abstracting prompt management, retrieval, memory, and agent orchestration. Developers can use'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='At the heart of LangChain lies the concept of chains, which are sequences of calls to LLMs and other tools. Chains can be simple, such as a single prompt fed to an LLM, or complex, involving multiple conditionally executed steps. LangChain makes it easy to compose and reuse chains using standard'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='knowledge is fetched and injected into the LLM prompt to enhance accuracy and reduce hallucination. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain also supports hybrid retrieval, which combines keyword-based (sparse) retrieval methods like BM25 with embedding-based (dense) retrieval. This ensures better recall by catching both exact term matches and semantically similar content. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='like web search, calculators, code execution environments, and custom APIs. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain agents operate using a planner-executor model, where the agent plans out a sequence of tool invocations to achieve a goal. This can include dynamic decision-making, branching logic, and context-aware memory use across steps. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain offers memory modules like ConversationBufferMemory and ConversationSummaryMemory. These allow the LLM to maintain awareness of previous conversation turns or summarize long interactions to fit within token limits. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Prompt engineering is central to LangChainâ€™s design. It provides templating capabilities, input variables, formatting options, and prompt chaining. Developers can reuse prompt templates across different chains and even nest them. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is compatible with multiple LLM providers including OpenAI, Anthropic, Cohere, Hugging Face, and more. This flexibility ensures that developers can switch between models without rewriting core logic. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain workflows are modular and composable. Components like retrievers, memories, agents, and chains can be easily combined and reused. This makes it ideal for building scalable, maintainable LLM applications. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is a multi-agent orchestration framework designed to build collaborative LLM-powered agents. It enables developers to structure agents into organized crews that work together to complete tasks by dividing responsibilities, sharing context, and dynamically communicating with one another. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI builds on the concept of autonomous agents but enhances it by allowing agents to form structured workflows. Each agent in a crew has a defined role, such as researcher, planner, or executor, and operates semi-independently within a collaborative context. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI agents are defined with a purpose, a goal, and a set of tools they can use. The framework ensures that each agent stays on task and contributes meaningfully to the overall crew objective. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content=\"One of CrewAI's core innovations is the use of agent context-sharing, where agents pass intermediate data to one another in a structured manner. This leads to emergent behaviors like delegation, consultation, and review among agents. (v2)\"),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is especially useful in multi-step workflows like market research, legal document analysis, product development, and coding assistants, where complex tasks benefit from specialization and collaboration. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='The framework supports full traceability of agent decisions and interactions, making debugging and transparency easier compared to standalone agent setups. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Developers can define a crew using a YAML or JSON-like configuration, specifying agent roles, goals, memory, and tools. CrewAI then orchestrates the agent loop and handles turn-taking and decision-making autonomously. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI supports multiple LLM backends and includes support for streaming, parallel execution, and asynchronous tool invocation, making it suitable for both fast-prototyping and production-ready systems. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='By enabling structured agent collaboration, CrewAI empowers teams to build intelligent systems that scale both horizontally (more agents) and vertically (more reasoning depth). (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is an open-source framework designed for developing applications powered by large language models (LLMs). It simplifies the process of building, managing, and scaling complex chains of thought by abstracting prompt management, retrieval, memory, and agent orchestration. Developers can use'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='At the heart of LangChain lies the concept of chains, which are sequences of calls to LLMs and other tools. Chains can be simple, such as a single prompt fed to an LLM, or complex, involving multiple conditionally executed steps. LangChain makes it easy to compose and reuse chains using standard'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='knowledge is fetched and injected into the LLM prompt to enhance accuracy and reduce hallucination. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain also supports hybrid retrieval, which combines keyword-based (sparse) retrieval methods like BM25 with embedding-based (dense) retrieval. This ensures better recall by catching both exact term matches and semantically similar content. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='like web search, calculators, code execution environments, and custom APIs. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain agents operate using a planner-executor model, where the agent plans out a sequence of tool invocations to achieve a goal. This can include dynamic decision-making, branching logic, and context-aware memory use across steps. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain offers memory modules like ConversationBufferMemory and ConversationSummaryMemory. These allow the LLM to maintain awareness of previous conversation turns or summarize long interactions to fit within token limits. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Prompt engineering is central to LangChainâ€™s design. It provides templating capabilities, input variables, formatting options, and prompt chaining. Developers can reuse prompt templates across different chains and even nest them. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is compatible with multiple LLM providers including OpenAI, Anthropic, Cohere, Hugging Face, and more. This flexibility ensures that developers can switch between models without rewriting core logic. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain workflows are modular and composable. Components like retrievers, memories, agents, and chains can be easily combined and reused. This makes it ideal for building scalable, maintainable LLM applications. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is a multi-agent orchestration framework designed to build collaborative LLM-powered agents. It enables developers to structure agents into organized crews that work together to complete tasks by dividing responsibilities, sharing context, and dynamically communicating with one another. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI builds on the concept of autonomous agents but enhances it by allowing agents to form structured workflows. Each agent in a crew has a defined role, such as researcher, planner, or executor, and operates semi-independently within a collaborative context. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI agents are defined with a purpose, a goal, and a set of tools they can use. The framework ensures that each agent stays on task and contributes meaningfully to the overall crew objective. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content=\"One of CrewAI's core innovations is the use of agent context-sharing, where agents pass intermediate data to one another in a structured manner. This leads to emergent behaviors like delegation, consultation, and review among agents. (v3)\"),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is especially useful in multi-step workflows like market research, legal document analysis, product development, and coding assistants, where complex tasks benefit from specialization and collaboration. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='The framework supports full traceability of agent decisions and interactions, making debugging and transparency easier compared to standalone agent setups. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Developers can define a crew using a YAML or JSON-like configuration, specifying agent roles, goals, memory, and tools. CrewAI then orchestrates the agent loop and handles turn-taking and decision-making autonomously. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI supports multiple LLM backends and includes support for streaming, parallel execution, and asynchronous tool invocation, making it suitable for both fast-prototyping and production-ready systems. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='By enabling structured agent collaboration, CrewAI empowers teams to build intelligent systems that scale both horizontally (more agents) and vertically (more reasoning depth). (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is an open-source framework designed for developing applications powered by large language models (LLMs). It simplifies the process of building, managing, and scaling complex chains of thought by abstracting prompt management, retrieval, memory, and agent orchestration. Developers can use'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='At the heart of LangChain lies the concept of chains, which are sequences of calls to LLMs and other tools. Chains can be simple, such as a single prompt fed to an LLM, or complex, involving multiple conditionally executed steps. LangChain makes it easy to compose and reuse chains using standard'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='knowledge is fetched and injected into the LLM prompt to enhance accuracy and reduce hallucination. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain also supports hybrid retrieval, which combines keyword-based (sparse) retrieval methods like BM25 with embedding-based (dense) retrieval. This ensures better recall by catching both exact term matches and semantically similar content. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='like web search, calculators, code execution environments, and custom APIs. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain agents operate using a planner-executor model, where the agent plans out a sequence of tool invocations to achieve a goal. This can include dynamic decision-making, branching logic, and context-aware memory use across steps. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain offers memory modules like ConversationBufferMemory and ConversationSummaryMemory. These allow the LLM to maintain awareness of previous conversation turns or summarize long interactions to fit within token limits. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Prompt engineering is central to LangChainâ€™s design. It provides templating capabilities, input variables, formatting options, and prompt chaining. Developers can reuse prompt templates across different chains and even nest them. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is compatible with multiple LLM providers including OpenAI, Anthropic, Cohere, Hugging Face, and more. This flexibility ensures that developers can switch between models without rewriting core logic. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain workflows are modular and composable. Components like retrievers, memories, agents, and chains can be easily combined and reused. This makes it ideal for building scalable, maintainable LLM applications. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is a multi-agent orchestration framework designed to build collaborative LLM-powered agents. It enables developers to structure agents into organized crews that work together to complete tasks by dividing responsibilities, sharing context, and dynamically communicating with one another. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI builds on the concept of autonomous agents but enhances it by allowing agents to form structured workflows. Each agent in a crew has a defined role, such as researcher, planner, or executor, and operates semi-independently within a collaborative context. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI agents are defined with a purpose, a goal, and a set of tools they can use. The framework ensures that each agent stays on task and contributes meaningfully to the overall crew objective. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content=\"One of CrewAI's core innovations is the use of agent context-sharing, where agents pass intermediate data to one another in a structured manner. This leads to emergent behaviors like delegation, consultation, and review among agents. (v4)\"),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is especially useful in multi-step workflows like market research, legal document analysis, product development, and coding assistants, where complex tasks benefit from specialization and collaboration. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='The framework supports full traceability of agent decisions and interactions, making debugging and transparency easier compared to standalone agent setups. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Developers can define a crew using a YAML or JSON-like configuration, specifying agent roles, goals, memory, and tools. CrewAI then orchestrates the agent loop and handles turn-taking and decision-making autonomously. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI supports multiple LLM backends and includes support for streaming, parallel execution, and asynchronous tool invocation, making it suitable for both fast-prototyping and production-ready systems. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='By enabling structured agent collaboration, CrewAI empowers teams to build intelligent systems that scale both horizontally (more agents) and vertically (more reasoning depth). (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is an open-source framework designed for developing applications powered by large language models (LLMs). It simplifies the process of building, managing, and scaling complex chains of thought by abstracting prompt management, retrieval, memory, and agent orchestration. Developers can use'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='At the heart of LangChain lies the concept of chains, which are sequences of calls to LLMs and other tools. Chains can be simple, such as a single prompt fed to an LLM, or complex, involving multiple conditionally executed steps. LangChain makes it easy to compose and reuse chains using standard'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='knowledge is fetched and injected into the LLM prompt to enhance accuracy and reduce hallucination. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain also supports hybrid retrieval, which combines keyword-based (sparse) retrieval methods like BM25 with embedding-based (dense) retrieval. This ensures better recall by catching both exact term matches and semantically similar content. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='like web search, calculators, code execution environments, and custom APIs. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain agents operate using a planner-executor model, where the agent plans out a sequence of tool invocations to achieve a goal. This can include dynamic decision-making, branching logic, and context-aware memory use across steps. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain offers memory modules like ConversationBufferMemory and ConversationSummaryMemory. These allow the LLM to maintain awareness of previous conversation turns or summarize long interactions to fit within token limits. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Prompt engineering is central to LangChainâ€™s design. It provides templating capabilities, input variables, formatting options, and prompt chaining. Developers can reuse prompt templates across different chains and even nest them. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is compatible with multiple LLM providers including OpenAI, Anthropic, Cohere, Hugging Face, and more. This flexibility ensures that developers can switch between models without rewriting core logic. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain workflows are modular and composable. Components like retrievers, memories, agents, and chains can be easily combined and reused. This makes it ideal for building scalable, maintainable LLM applications. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is a multi-agent orchestration framework designed to build collaborative LLM-powered agents. It enables developers to structure agents into organized crews that work together to complete tasks by dividing responsibilities, sharing context, and dynamically communicating with one another. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI builds on the concept of autonomous agents but enhances it by allowing agents to form structured workflows. Each agent in a crew has a defined role, such as researcher, planner, or executor, and operates semi-independently within a collaborative context. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI agents are defined with a purpose, a goal, and a set of tools they can use. The framework ensures that each agent stays on task and contributes meaningfully to the overall crew objective. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content=\"One of CrewAI's core innovations is the use of agent context-sharing, where agents pass intermediate data to one another in a structured manner. This leads to emergent behaviors like delegation, consultation, and review among agents. (v5)\"),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is especially useful in multi-step workflows like market research, legal document analysis, product development, and coding assistants, where complex tasks benefit from specialization and collaboration. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='The framework supports full traceability of agent decisions and interactions, making debugging and transparency easier compared to standalone agent setups. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Developers can define a crew using a YAML or JSON-like configuration, specifying agent roles, goals, memory, and tools. CrewAI then orchestrates the agent loop and handles turn-taking and decision-making autonomously. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI supports multiple LLM backends and includes support for streaming, parallel execution, and asynchronous tool invocation, making it suitable for both fast-prototyping and production-ready systems. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='By enabling structured agent collaboration, CrewAI empowers teams to build intelligent systems that scale both horizontally (more agents) and vertically (more reasoning depth). (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is an open-source framework designed for developing applications powered by large language models (LLMs). It simplifies the process of building, managing, and scaling complex chains of thought by abstracting prompt management, retrieval, memory, and agent orchestration. Developers can use'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='At the heart of LangChain lies the concept of chains, which are sequences of calls to LLMs and other tools. Chains can be simple, such as a single prompt fed to an LLM, or complex, involving multiple conditionally executed steps. LangChain makes it easy to compose and reuse chains using standard'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='knowledge is fetched and injected into the LLM prompt to enhance accuracy and reduce hallucination. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain also supports hybrid retrieval, which combines keyword-based (sparse) retrieval methods like BM25 with embedding-based (dense) retrieval. This ensures better recall by catching both exact term matches and semantically similar content. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='like web search, calculators, code execution environments, and custom APIs. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain agents operate using a planner-executor model, where the agent plans out a sequence of tool invocations to achieve a goal. This can include dynamic decision-making, branching logic, and context-aware memory use across steps. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain offers memory modules like ConversationBufferMemory and ConversationSummaryMemory. These allow the LLM to maintain awareness of previous conversation turns or summarize long interactions to fit within token limits. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Prompt engineering is central to LangChainâ€™s design. It provides templating capabilities, input variables, formatting options, and prompt chaining. Developers can reuse prompt templates across different chains and even nest them. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is compatible with multiple LLM providers including OpenAI, Anthropic, Cohere, Hugging Face, and more. This flexibility ensures that developers can switch between models without rewriting core logic. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain workflows are modular and composable. Components like retrievers, memories, agents, and chains can be easily combined and reused. This makes it ideal for building scalable, maintainable LLM applications. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is a multi-agent orchestration framework designed to build collaborative LLM-powered agents. It enables developers to structure agents into organized crews that work together to complete tasks by dividing responsibilities, sharing context, and dynamically communicating with one another. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI builds on the concept of autonomous agents but enhances it by allowing agents to form structured workflows. Each agent in a crew has a defined role, such as researcher, planner, or executor, and operates semi-independently within a collaborative context. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI agents are defined with a purpose, a goal, and a set of tools they can use. The framework ensures that each agent stays on task and contributes meaningfully to the overall crew objective. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content=\"One of CrewAI's core innovations is the use of agent context-sharing, where agents pass intermediate data to one another in a structured manner. This leads to emergent behaviors like delegation, consultation, and review among agents. (v6)\"),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is especially useful in multi-step workflows like market research, legal document analysis, product development, and coding assistants, where complex tasks benefit from specialization and collaboration. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='The framework supports full traceability of agent decisions and interactions, making debugging and transparency easier compared to standalone agent setups. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Developers can define a crew using a YAML or JSON-like configuration, specifying agent roles, goals, memory, and tools. CrewAI then orchestrates the agent loop and handles turn-taking and decision-making autonomously. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI supports multiple LLM backends and includes support for streaming, parallel execution, and asynchronous tool invocation, making it suitable for both fast-prototyping and production-ready systems. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='By enabling structured agent collaboration, CrewAI empowers teams to build intelligent systems that scale both horizontally (more agents) and vertically (more reasoning depth). (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is an open-source framework designed for developing applications powered by large language models (LLMs). It simplifies the process of building, managing, and scaling complex chains of thought by abstracting prompt management, retrieval, memory, and agent orchestration. Developers can use'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='At the heart of LangChain lies the concept of chains, which are sequences of calls to LLMs and other tools. Chains can be simple, such as a single prompt fed to an LLM, or complex, involving multiple conditionally executed steps. LangChain makes it easy to compose and reuse chains using standard'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='knowledge is fetched and injected into the LLM prompt to enhance accuracy and reduce hallucination. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain also supports hybrid retrieval, which combines keyword-based (sparse) retrieval methods like BM25 with embedding-based (dense) retrieval. This ensures better recall by catching both exact term matches and semantically similar content. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='like web search, calculators, code execution environments, and custom APIs. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain agents operate using a planner-executor model, where the agent plans out a sequence of tool invocations to achieve a goal. This can include dynamic decision-making, branching logic, and context-aware memory use across steps. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain offers memory modules like ConversationBufferMemory and ConversationSummaryMemory. These allow the LLM to maintain awareness of previous conversation turns or summarize long interactions to fit within token limits. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Prompt engineering is central to LangChainâ€™s design. It provides templating capabilities, input variables, formatting options, and prompt chaining. Developers can reuse prompt templates across different chains and even nest them. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is compatible with multiple LLM providers including OpenAI, Anthropic, Cohere, Hugging Face, and more. This flexibility ensures that developers can switch between models without rewriting core logic. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain workflows are modular and composable. Components like retrievers, memories, agents, and chains can be easily combined and reused. This makes it ideal for building scalable, maintainable LLM applications. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is a multi-agent orchestration framework designed to build collaborative LLM-powered agents. It enables developers to structure agents into organized crews that work together to complete tasks by dividing responsibilities, sharing context, and dynamically communicating with one another. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI builds on the concept of autonomous agents but enhances it by allowing agents to form structured workflows. Each agent in a crew has a defined role, such as researcher, planner, or executor, and operates semi-independently within a collaborative context. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI agents are defined with a purpose, a goal, and a set of tools they can use. The framework ensures that each agent stays on task and contributes meaningfully to the overall crew objective. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content=\"One of CrewAI's core innovations is the use of agent context-sharing, where agents pass intermediate data to one another in a structured manner. This leads to emergent behaviors like delegation, consultation, and review among agents. (v7)\"),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is especially useful in multi-step workflows like market research, legal document analysis, product development, and coding assistants, where complex tasks benefit from specialization and collaboration. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='The framework supports full traceability of agent decisions and interactions, making debugging and transparency easier compared to standalone agent setups. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Developers can define a crew using a YAML or JSON-like configuration, specifying agent roles, goals, memory, and tools. CrewAI then orchestrates the agent loop and handles turn-taking and decision-making autonomously. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI supports multiple LLM backends and includes support for streaming, parallel execution, and asynchronous tool invocation, making it suitable for both fast-prototyping and production-ready systems. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='By enabling structured agent collaboration, CrewAI empowers teams to build intelligent systems that scale both horizontally (more agents) and vertically (more reasoning depth). (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is an open-source framework designed for developing applications powered by large language models (LLMs). It simplifies the process of building, managing, and scaling complex chains of thought by abstracting prompt management, retrieval, memory, and agent orchestration. Developers can use'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='At the heart of LangChain lies the concept of chains, which are sequences of calls to LLMs and other tools. Chains can be simple, such as a single prompt fed to an LLM, or complex, involving multiple conditionally executed steps. LangChain makes it easy to compose and reuse chains using standard'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='knowledge is fetched and injected into the LLM prompt to enhance accuracy and reduce hallucination. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain also supports hybrid retrieval, which combines keyword-based (sparse) retrieval methods like BM25 with embedding-based (dense) retrieval. This ensures better recall by catching both exact term matches and semantically similar content. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='like web search, calculators, code execution environments, and custom APIs. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain agents operate using a planner-executor model, where the agent plans out a sequence of tool invocations to achieve a goal. This can include dynamic decision-making, branching logic, and context-aware memory use across steps. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain offers memory modules like ConversationBufferMemory and ConversationSummaryMemory. These allow the LLM to maintain awareness of previous conversation turns or summarize long interactions to fit within token limits. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Prompt engineering is central to LangChainâ€™s design. It provides templating capabilities, input variables, formatting options, and prompt chaining. Developers can reuse prompt templates across different chains and even nest them. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is compatible with multiple LLM providers including OpenAI, Anthropic, Cohere, Hugging Face, and more. This flexibility ensures that developers can switch between models without rewriting core logic. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain workflows are modular and composable. Components like retrievers, memories, agents, and chains can be easily combined and reused. This makes it ideal for building scalable, maintainable LLM applications. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is a multi-agent orchestration framework designed to build collaborative LLM-powered agents. It enables developers to structure agents into organized crews that work together to complete tasks by dividing responsibilities, sharing context, and dynamically communicating with one another. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI builds on the concept of autonomous agents but enhances it by allowing agents to form structured workflows. Each agent in a crew has a defined role, such as researcher, planner, or executor, and operates semi-independently within a collaborative context. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI agents are defined with a purpose, a goal, and a set of tools they can use. The framework ensures that each agent stays on task and contributes meaningfully to the overall crew objective. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content=\"One of CrewAI's core innovations is the use of agent context-sharing, where agents pass intermediate data to one another in a structured manner. This leads to emergent behaviors like delegation, consultation, and review among agents. (v8)\"),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is especially useful in multi-step workflows like market research, legal document analysis, product development, and coding assistants, where complex tasks benefit from specialization and collaboration. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='The framework supports full traceability of agent decisions and interactions, making debugging and transparency easier compared to standalone agent setups. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Developers can define a crew using a YAML or JSON-like configuration, specifying agent roles, goals, memory, and tools. CrewAI then orchestrates the agent loop and handles turn-taking and decision-making autonomously. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI supports multiple LLM backends and includes support for streaming, parallel execution, and asynchronous tool invocation, making it suitable for both fast-prototyping and production-ready systems. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='By enabling structured agent collaboration, CrewAI empowers teams to build intelligent systems that scale both horizontally (more agents) and vertically (more reasoning depth). (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is an open-source framework designed for developing applications powered by large language models (LLMs). It simplifies the process of building, managing, and scaling complex chains of thought by abstracting prompt management, retrieval, memory, and agent orchestration. Developers can use'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='At the heart of LangChain lies the concept of chains, which are sequences of calls to LLMs and other tools. Chains can be simple, such as a single prompt fed to an LLM, or complex, involving multiple conditionally executed steps. LangChain makes it easy to compose and reuse chains using standard'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='knowledge is fetched and injected into the LLM prompt to enhance accuracy and reduce hallucination. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain also supports hybrid retrieval, which combines keyword-based (sparse) retrieval methods like BM25 with embedding-based (dense) retrieval. This ensures better recall by catching both exact term matches and semantically similar content. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='like web search, calculators, code execution environments, and custom APIs. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain agents operate using a planner-executor model, where the agent plans out a sequence of tool invocations to achieve a goal. This can include dynamic decision-making, branching logic, and context-aware memory use across steps. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain offers memory modules like ConversationBufferMemory and ConversationSummaryMemory. These allow the LLM to maintain awareness of previous conversation turns or summarize long interactions to fit within token limits. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Prompt engineering is central to LangChainâ€™s design. It provides templating capabilities, input variables, formatting options, and prompt chaining. Developers can reuse prompt templates across different chains and even nest them. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is compatible with multiple LLM providers including OpenAI, Anthropic, Cohere, Hugging Face, and more. This flexibility ensures that developers can switch between models without rewriting core logic. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain workflows are modular and composable. Components like retrievers, memories, agents, and chains can be easily combined and reused. This makes it ideal for building scalable, maintainable LLM applications. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is a multi-agent orchestration framework designed to build collaborative LLM-powered agents. It enables developers to structure agents into organized crews that work together to complete tasks by dividing responsibilities, sharing context, and dynamically communicating with one another. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI builds on the concept of autonomous agents but enhances it by allowing agents to form structured workflows. Each agent in a crew has a defined role, such as researcher, planner, or executor, and operates semi-independently within a collaborative context. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI agents are defined with a purpose, a goal, and a set of tools they can use. The framework ensures that each agent stays on task and contributes meaningfully to the overall crew objective. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content=\"One of CrewAI's core innovations is the use of agent context-sharing, where agents pass intermediate data to one another in a structured manner. This leads to emergent behaviors like delegation, consultation, and review among agents. (v9)\"),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is especially useful in multi-step workflows like market research, legal document analysis, product development, and coding assistants, where complex tasks benefit from specialization and collaboration. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='The framework supports full traceability of agent decisions and interactions, making debugging and transparency easier compared to standalone agent setups. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Developers can define a crew using a YAML or JSON-like configuration, specifying agent roles, goals, memory, and tools. CrewAI then orchestrates the agent loop and handles turn-taking and decision-making autonomously. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI supports multiple LLM backends and includes support for streaming, parallel execution, and asynchronous tool invocation, making it suitable for both fast-prototyping and production-ready systems. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='By enabling structured agent collaboration, CrewAI empowers teams to build intelligent systems that scale both horizontally (more agents) and vertically (more reasoning depth). (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is an open-source framework designed for developing applications powered by large language models (LLMs). It simplifies the process of building, managing, and scaling complex chains of thought by abstracting prompt management, retrieval, memory, and agent orchestration. Developers can use'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='At the heart of LangChain lies the concept of chains, which are sequences of calls to LLMs and other tools. Chains can be simple, such as a single prompt fed to an LLM, or complex, involving multiple conditionally executed steps. LangChain makes it easy to compose and reuse chains using standard'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='knowledge is fetched and injected into the LLM prompt to enhance accuracy and reduce hallucination. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain also supports hybrid retrieval, which combines keyword-based (sparse) retrieval methods like BM25 with embedding-based (dense) retrieval. This ensures better recall by catching both exact term matches and semantically similar content. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='like web search, calculators, code execution environments, and custom APIs. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain agents operate using a planner-executor model, where the agent plans out a sequence of tool invocations to achieve a goal. This can include dynamic decision-making, branching logic, and context-aware memory use across steps. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain offers memory modules like ConversationBufferMemory and ConversationSummaryMemory. These allow the LLM to maintain awareness of previous conversation turns or summarize long interactions to fit within token limits. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Prompt engineering is central to LangChainâ€™s design. It provides templating capabilities, input variables, formatting options, and prompt chaining. Developers can reuse prompt templates across different chains and even nest them. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is compatible with multiple LLM providers including OpenAI, Anthropic, Cohere, Hugging Face, and more. This flexibility ensures that developers can switch between models without rewriting core logic. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain workflows are modular and composable. Components like retrievers, memories, agents, and chains can be easily combined and reused. This makes it ideal for building scalable, maintainable LLM applications. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is a multi-agent orchestration framework designed to build collaborative LLM-powered agents. It enables developers to structure agents into organized crews that work together to complete tasks by dividing responsibilities, sharing context, and dynamically communicating with one another.'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='and dynamically communicating with one another. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI builds on the concept of autonomous agents but enhances it by allowing agents to form structured workflows. Each agent in a crew has a defined role, such as researcher, planner, or executor, and operates semi-independently within a collaborative context. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI agents are defined with a purpose, a goal, and a set of tools they can use. The framework ensures that each agent stays on task and contributes meaningfully to the overall crew objective. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content=\"One of CrewAI's core innovations is the use of agent context-sharing, where agents pass intermediate data to one another in a structured manner. This leads to emergent behaviors like delegation, consultation, and review among agents. (v10)\"),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is especially useful in multi-step workflows like market research, legal document analysis, product development, and coding assistants, where complex tasks benefit from specialization and collaboration. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='The framework supports full traceability of agent decisions and interactions, making debugging and transparency easier compared to standalone agent setups. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Developers can define a crew using a YAML or JSON-like configuration, specifying agent roles, goals, memory, and tools. CrewAI then orchestrates the agent loop and handles turn-taking and decision-making autonomously. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI supports multiple LLM backends and includes support for streaming, parallel execution, and asynchronous tool invocation, making it suitable for both fast-prototyping and production-ready systems. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='By enabling structured agent collaboration, CrewAI empowers teams to build intelligent systems that scale both horizontally (more agents) and vertically (more reasoning depth). (v10)')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = TextLoader(file_path=\"langchain_crewai_dataset.txt\")\n",
    "documents = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300, chunk_overlap=50\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(documents=documents)\n",
    "\n",
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de41909",
   "metadata": {},
   "source": [
    "## Create Vector Store and Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4beb21a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000027E4A9A1E80>, search_type='mmr', search_kwargs={'k': 5})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store = FAISS.from_documents(\n",
    "    documents=chunks, \n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\"k\":5}\n",
    ")\n",
    "\n",
    "retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f78d32",
   "metadata": {},
   "source": [
    "## Query Expansion Prompt and Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c29efc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template='\\nYou are a helpful assistant. Expand the following query to improve document retrieval \\nby adding relevant synonyms, technical terms, and useful context.\\n\\nOriginal query: \"{query}\"\\n\\nExpanded query:\\n')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_expansion_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are a helpful assistant. Expand the following query to improve document retrieval \n",
    "by adding relevant synonyms, technical terms, and useful context.\n",
    "\n",
    "Original query: \"{query}\"\n",
    "\n",
    "Expanded query:\n",
    "\"\"\")\n",
    "\n",
    "query_expansion_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e0b7d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template='\\nYou are a helpful assistant. Expand the following query to improve document retrieval \\nby adding relevant synonyms, technical terms, and useful context.\\n\\nOriginal query: \"{query}\"\\n\\nExpanded query:\\n')\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000027E47B1EEA0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000027E4822B260>, root_client=<openai.OpenAI object at 0x0000027E47160F20>, root_async_client=<openai.AsyncOpenAI object at 0x0000027E47C41340>, model_name='o4-mini', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_expansion_chain = query_expansion_prompt | llm | StrOutputParser()\n",
    "\n",
    "query_expansion_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18a55c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Expanded query:  \\n“LangChain memory” OR “LangChain memory management” OR “LangChain memory modules” OR “LangChain memory primitives” OR “conversation memory” OR “conversation buffer memory” OR “persistent memory backend” OR “ephemeral memory” OR “long-term memory” OR “memory retrieval” OR “vector-based memory store” OR “RAG (retrieval-augmented generation) pipelines” OR “context window management” OR “memory chain components” OR “LLM memory augmentation” OR “Python LangChain framework” OR “conversational AI memory” OR “chatbot memory strategies” OR “BaseMemory” OR “ConversationBufferMemory” OR “ConversationSummaryMemory” OR “memory backends Redis Chroma Qdrant Weaviate ElasticSearch SQL”'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Langchain memory\"\n",
    "\n",
    "query_expansion_chain.invoke({\"query\":query})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be193af2",
   "metadata": {},
   "source": [
    "## RAG Prompt and Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e67a7f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, template='\\nAnswer the question based on the context below.\\n\\nContext:\\n{context}\\n\\nQuestion: {input}\\n')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prompt = PromptTemplate.from_template(\"\"\"\n",
    "Answer the question based on the context below.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {input}\n",
    "\"\"\")\n",
    "\n",
    "final_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b141f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| PromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, template='\\nAnswer the question based on the context below.\\n\\nContext:\\n{context}\\n\\nQuestion: {input}\\n')\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000027E47B1EEA0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000027E4822B260>, root_client=<openai.OpenAI object at 0x0000027E47160F20>, root_async_client=<openai.AsyncOpenAI object at 0x0000027E47C41340>, model_name='o4-mini', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_chain = create_stuff_documents_chain(\n",
    "    llm=llm,\n",
    "    prompt=final_prompt\n",
    ")\n",
    "\n",
    "document_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c89fbcc",
   "metadata": {},
   "source": [
    "## Full RAG pipeline with query expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63e0707c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  input: RunnableLambda(...),\n",
       "  context: RunnableLambda(...)\n",
       "}\n",
       "| RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "    context: RunnableLambda(format_docs)\n",
       "  }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "  | PromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, template='\\nAnswer the question based on the context below.\\n\\nContext:\\n{context}\\n\\nQuestion: {input}\\n')\n",
       "  | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000027E47B1EEA0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000027E4822B260>, root_client=<openai.OpenAI object at 0x0000027E47160F20>, root_async_client=<openai.AsyncOpenAI object at 0x0000027E47C41340>, model_name='o4-mini', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "  | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_pipeline = (\n",
    "    RunnableMap(\n",
    "        {\n",
    "            \"input\": lambda x: x[\"input\"],\n",
    "            \"context\": lambda x: retriever.invoke(query_expansion_chain.invoke({\"query\": x[\"input\"]}))\n",
    "        }\n",
    "    )\n",
    "    | document_chain\n",
    ")\n",
    "\n",
    "rag_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ecce2c",
   "metadata": {},
   "source": [
    "## Run Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7abf076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded query:\n",
      "\n",
      "“LangChain memory support” OR “LangChain memory modules” OR “LangChain memory backends” OR “memory strategies in LangChain” OR “session memory management” OR “state management in LangChain” OR “conversation buffer memory” OR “chat memory” OR “short-term memory” OR “long-term memory” OR “ephemeral memory” OR “persistent memory” OR “summary memory” OR “vector memory” OR “external vectorstore” OR “RedisMemory” OR “MongoDBMemory” OR “SQLDatabaseMemory” OR “memory store” OR “memory architecture for LLM agents”\n"
     ]
    }
   ],
   "source": [
    "query = \"What types of memory does LangChain support?\"\n",
    "\n",
    "print(query_expansion_chain.invoke({\"query\": {\"input\":query}}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60945a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Answer:\n",
      " LangChain’s built-in conversational memories fall into two main categories:\n",
      "\n",
      "  1. ConversationBufferMemory  \n",
      "     – Keeps the full dialogue history in memory so the LLM can “see” all prior turns.  \n",
      "\n",
      "  2. ConversationSummaryMemory  \n",
      "     – Periodically summarizes the chat history into a concise form, letting you preserve context while staying within token limits.\n"
     ]
    }
   ],
   "source": [
    "response = rag_pipeline.invoke(input={\"input\":query})\n",
    "\n",
    "print(\"✅ Answer:\\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e44d05a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded query:\n",
      "\n",
      "(\"CrewAI\" OR \"Crew AI\" OR CrewAI-based) AND (agent OR agents OR “autonomous agent” OR “intelligent agent” OR “multi-agent system” OR “agent-based modeling” OR “collaborative AI” OR “AI-driven crew member”)  \n",
      "AND (“task allocation” OR orchestration OR scheduling OR “workflow automation” OR “decision support” OR “real-time coordination” OR “mission planning”)  \n",
      "AND (“reinforcement learning” OR “multi-agent reinforcement learning” OR “deep learning” OR “machine learning” OR “neural network” OR RPA OR “robotic process automation”)  \n",
      "AND (“human-AI teaming” OR “human-machine collaboration” OR “workforce augmentation” OR “crew management” OR “crew scheduling” OR “crew operations”)  \n",
      "AND (maritime OR aerospace OR aviation OR space OR logistics OR manufacturing OR warehousing OR “mission-critical operations”)  \n",
      "\n",
      "Key synonyms & terms added:  \n",
      "• autonomous agents, intelligent agents, multi-agent systems  \n",
      "• agent-based modeling, collaborative robots (cobots)  \n",
      "• reinforcement learning, orchestration, RPA  \n",
      "• human-AI teaming, workforce augmentation  \n",
      "• domain contexts: maritime, aerospace, logistics, manufacturing\n"
     ]
    }
   ],
   "source": [
    "query = \"CrewAI agents?\"\n",
    "\n",
    "print(query_expansion_chain.invoke({\"query\": {\"input\":query}}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ffe67b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Answer:\n",
      " CrewAI agents are purpose‐driven autonomous workers that collaborate in a structured workflow.  Each agent is defined by:  \n",
      "• A specific role (e.g., researcher, planner, executor)  \n",
      "• A clear purpose and goal within the overall mission  \n",
      "• A tailored toolset they may draw on to perform their tasks  \n",
      "\n",
      "They operate semi-independently—staying on task, using their tools, and coordinating with fellow agents—so that the crew as a whole can efficiently reach its objective.\n"
     ]
    }
   ],
   "source": [
    "response = rag_pipeline.invoke(input={\"input\":query})\n",
    "\n",
    "print(\"✅ Answer:\\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55c1269",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG-Bootcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
