{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e83b2980",
   "metadata": {},
   "source": [
    "## Setup and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1aa6ab81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from langchain.chat_models import init_chat_model\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b633a72f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc668fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e0d3250",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = init_chat_model(\"openai:gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31867b5f",
   "metadata": {},
   "source": [
    "## Creating Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9aacdcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad1e1e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cache_model(query):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    if model_cache.get(query):\n",
    "        print(\"**CACHE HIT**\")\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time-start_time\n",
    "        print(f\"EXECUTION TIME: {elapsed_time:.2f} seconds\")\n",
    "        return model_cache.get(query)\n",
    "    else:\n",
    "        print(\"***CACHE MISS – EXECUTING MODEL***\")\n",
    "        start_time = time.time()\n",
    "        response = llm.invoke(query)\n",
    "        end_time = time.time()\n",
    "        elapsed = end_time - start_time\n",
    "        print(f\"EXECUTION TIME: {elapsed:.2f} seconds\")\n",
    "        model_cache[query] = response\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd3c8892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***CACHE MISS – EXECUTING MODEL***\n",
      "EXECUTION TIME: 2.12 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 8, 'total_tokens': 17, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CXkxkYnt2pytsW9cJxjLx0RFzv9Ja', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--dd6916e7-3fa0-446e-ab7d-8bb414f9f2b1-0', usage_metadata={'input_tokens': 8, 'output_tokens': 9, 'total_tokens': 17, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = cache_model(\"hi\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "884d381d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***CACHE MISS – EXECUTING MODEL***\n",
      "EXECUTION TIME: 15.08 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='LangGraph is an emerging concept that merges natural language processing (NLP) with graph-based data structures to enhance the way machines understand and generate human language. With the rapid advancements in artificial intelligence (AI) and machine learning (ML), traditional methods of language processing are increasingly supplemented or even replaced by graph-based approaches. LangGraph seeks to leverage the relational and semantic relationships between words, phrases, and concepts by representing language as a graph.\\n\\nAt its core, LangGraph operates on the principle that relationships matter in language. In typical NLP applications, words and sentences are treated in isolation or as sequential data, potentially losing the intricate web of meanings and connections that define language. By structuring language data as graphs, where nodes represent words or concepts and edges represent relationships (such as synonymy, antonymy, or contextual usage), LangGraph allows for a more nuanced understanding of language.\\n\\nOne of the primary benefits of using a graph-centric approach is the capability to handle ambiguous language. Words often have multiple meanings (polysemy), and their meanings can shift based on context. In a graph representation, the surrounding nodes (contextual clues) can help disambiguate meanings, enabling systems to infer the intended meaning more effectively. This is particularly useful in applications like chatbots and virtual assistants, where understanding user intent is crucial for effective interaction.\\n\\nLangGraph also benefits from existing graph-based algorithms and techniques, such as those used in graph neural networks (GNNs). GNNs have proven successful in various domains, including social networks and biological data analysis, due to their ability to capture relational data patterns. By applying these techniques to language, LangGraph can improve tasks like sentiment analysis, text classification, and even machine translation by considering how words relate within larger contextual frameworks rather than in isolation.\\n\\nMoreover, LangGraph can leverage knowledge graphs, which encapsulate information about entities and their interrelations, providing a rich context for understanding language. With knowledge graphs, machines can access vast amounts of relational data, which can enhance the quality of language generation and comprehension tasks. This combination can lead to more coherent and contextually aware AI-generated texts, making interactions with AI systems feel more natural and human-like.\\n\\nAnother intriguing aspect of LangGraph is its potential for personalization and adaptation in language models. By creating user-specific language graphs that incorporate individual vocabulary choices, preferences, and prior interactions, AI systems could tailor their responses and language use to meet the unique needs of different users. This could greatly enhance user experience and engagement, particularly in applications like personalized tutoring platforms or customer service bots.\\n\\nDespite its promise, the development of LangGraph is not without challenges. The computational complexity associated with graph structures can be a barrier, and ensuring that these models scale effectively remains a subject of research. Furthermore, the integration of multimodal data (such as images or audio) into a graph framework presents additional complexities.\\n\\nIn conclusion, LangGraph represents a significant shift in how we approach language processing by incorporating graph theory into NLP. Its ability to capture the relational nuances of language offers a fresh perspective in tackling common challenges faced in AI communication. As research evolves, LangGraph has the potential to revolutionize various applications, enabling machines to understand and generate human language with unprecedented accuracy and contextual awareness. The intersection of graphs and language processing could pave the way for more intelligent, responsive, and human-centric AI systems.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 669, 'prompt_tokens': 18, 'total_tokens': 687, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CXkyNHs8rez0K6tuPsDz1wVfiUTgy', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--06eb0672-c4b0-44fa-8da0-0db4565dadbe-0', usage_metadata={'input_tokens': 18, 'output_tokens': 669, 'total_tokens': 687, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"can you give me 500 words on langgraph?\"\n",
    "response = cache_model(query)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09f7d255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**CACHE HIT**\n",
      "EXECUTION TIME: 0.00 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 8, 'total_tokens': 17, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CXkxkYnt2pytsW9cJxjLx0RFzv9Ja', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--dd6916e7-3fa0-446e-ab7d-8bb414f9f2b1-0', usage_metadata={'input_tokens': 8, 'output_tokens': 9, 'total_tokens': 17, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = cache_model(\"hi\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04fd8d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**CACHE HIT**\n",
      "EXECUTION TIME: 0.00 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='LangGraph is an emerging concept that merges natural language processing (NLP) with graph-based data structures to enhance the way machines understand and generate human language. With the rapid advancements in artificial intelligence (AI) and machine learning (ML), traditional methods of language processing are increasingly supplemented or even replaced by graph-based approaches. LangGraph seeks to leverage the relational and semantic relationships between words, phrases, and concepts by representing language as a graph.\\n\\nAt its core, LangGraph operates on the principle that relationships matter in language. In typical NLP applications, words and sentences are treated in isolation or as sequential data, potentially losing the intricate web of meanings and connections that define language. By structuring language data as graphs, where nodes represent words or concepts and edges represent relationships (such as synonymy, antonymy, or contextual usage), LangGraph allows for a more nuanced understanding of language.\\n\\nOne of the primary benefits of using a graph-centric approach is the capability to handle ambiguous language. Words often have multiple meanings (polysemy), and their meanings can shift based on context. In a graph representation, the surrounding nodes (contextual clues) can help disambiguate meanings, enabling systems to infer the intended meaning more effectively. This is particularly useful in applications like chatbots and virtual assistants, where understanding user intent is crucial for effective interaction.\\n\\nLangGraph also benefits from existing graph-based algorithms and techniques, such as those used in graph neural networks (GNNs). GNNs have proven successful in various domains, including social networks and biological data analysis, due to their ability to capture relational data patterns. By applying these techniques to language, LangGraph can improve tasks like sentiment analysis, text classification, and even machine translation by considering how words relate within larger contextual frameworks rather than in isolation.\\n\\nMoreover, LangGraph can leverage knowledge graphs, which encapsulate information about entities and their interrelations, providing a rich context for understanding language. With knowledge graphs, machines can access vast amounts of relational data, which can enhance the quality of language generation and comprehension tasks. This combination can lead to more coherent and contextually aware AI-generated texts, making interactions with AI systems feel more natural and human-like.\\n\\nAnother intriguing aspect of LangGraph is its potential for personalization and adaptation in language models. By creating user-specific language graphs that incorporate individual vocabulary choices, preferences, and prior interactions, AI systems could tailor their responses and language use to meet the unique needs of different users. This could greatly enhance user experience and engagement, particularly in applications like personalized tutoring platforms or customer service bots.\\n\\nDespite its promise, the development of LangGraph is not without challenges. The computational complexity associated with graph structures can be a barrier, and ensuring that these models scale effectively remains a subject of research. Furthermore, the integration of multimodal data (such as images or audio) into a graph framework presents additional complexities.\\n\\nIn conclusion, LangGraph represents a significant shift in how we approach language processing by incorporating graph theory into NLP. Its ability to capture the relational nuances of language offers a fresh perspective in tackling common challenges faced in AI communication. As research evolves, LangGraph has the potential to revolutionize various applications, enabling machines to understand and generate human language with unprecedented accuracy and contextual awareness. The intersection of graphs and language processing could pave the way for more intelligent, responsive, and human-centric AI systems.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 669, 'prompt_tokens': 18, 'total_tokens': 687, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CXkyNHs8rez0K6tuPsDz1wVfiUTgy', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--06eb0672-c4b0-44fa-8da0-0db4565dadbe-0', usage_metadata={'input_tokens': 18, 'output_tokens': 669, 'total_tokens': 687, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"can you give me 500 words on langgraph?\"\n",
    "response = cache_model(query)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ca7822e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***CACHE MISS – EXECUTING MODEL***\n",
      "EXECUTION TIME: 14.50 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='LangGraph is a conceptual framework that brings together language processing and graph theory to facilitate advanced natural language understanding and generation. At its core, LangGraph treats language as a structured graph, where nodes represent linguistic units (such as words, phrases, or entire sentences) and edges depict the relationships between these units. This innovative approach leverages the inherent connectivity and structural properties of graphs to enhance various aspects of natural language processing (NLP).\\n\\nIn traditional NLP methods, language data is often treated in a sequential manner, utilizing models like n-grams or recurrent neural networks (RNNs) that analyze text in a linear fashion. While these models have made impressive strides, they often struggle with capturing long-range dependencies and contextual relationships inherent in human language. LangGraph addresses these challenges by enabling the representation of language in a more flexible and interconnected format.\\n\\nOne of the primary advantages of LangGraph is its ability to represent complex relationships among linguistic elements. For instance, in a sentence, words may not only be linked through direct grammatical connections but also through semantic meanings and syntactic functions. By modeling these relationships in a graph structure, LangGraph allows for richer representations where nuanced meanings and contextual cues can be highlighted. This can enhance tasks such as semantic parsing, where the goal is to derive meaning from sentences, and information extraction, where specific data points need to be identified from text.\\n\\nFurthermore, LangGraph can improve the efficiency of machine learning algorithms by leveraging graph-based techniques. For instance, graph convolutional networks (GCNs) can be employed to process the language graph, enabling the model to learn from the interconnected structure of the graph rather than just linear sequences. This can lead to improved performance in various tasks, such as sentiment analysis, where understanding the relationships between words can provide deeper insights into the emotional tone of a text.\\n\\nIn addition to theoretical contributions, LangGraph has practical applications. In dialogue systems and chatbots, for example, building a LangGraph can help maintain context over the course of a conversation. Instead of processing each input independently, the system can maintain a dynamic graph that evolves with user interactions, allowing for more contextual and relevant responses. This is especially important in complex dialogues where understanding past interactions can significantly affect future responses.\\n\\nMoreover, LangGraph can facilitate multilingual NLP applications. Since languages differ in structure and vocabulary, a graph-based representation can provide a universal framework that highlights relationships common across different languages. By transforming language into a graph, multilingual models can leverage shared semantic similarities, making it easier to develop systems that operate in multiple languages without needing extensive training data for each.\\n\\nFinally, as the field of NLP continues to evolve, LangGraph represents a promising direction that combines the strengths of graph theory with linguistic analysis. By offering a framework that emphasizes relationships and structures within language, LangGraph could lead to breakthroughs in understanding and generating human language. As research progresses, it has the potential to refine current methodologies and pave the way for more intelligent, context-aware NLP systems that can understand, interpret, and generate language in a manner that resonates with human cognition. \\n\\nIn conclusion, LangGraph not only enhances our understanding of language structure but also opens up new avenues for innovation in natural language processing, making it a significant area of interest for researchers and developers alike.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 647, 'prompt_tokens': 16, 'total_tokens': 663, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CXkzKYgjOlgyyAAIITKlbKjt3Xv77', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--f576f73a-cbc1-4897-9148-12683b695b60-0', usage_metadata={'input_tokens': 16, 'output_tokens': 647, 'total_tokens': 663, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"give me 500 words on langgraph?\"\n",
    "response = cache_model(query)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86267af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG-Bootcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
